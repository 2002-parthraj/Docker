****Index****

Docker Explanation
Docker-installation
Docker-hub
Basic-commands
inspect-container
volumes
copy-commands
export-commands
network
Multi-option Docker Run Command
How to make Dockerfile
Dockerfile Example




**********************************Docker Explanation**********************************

1. What is Docker ?

"Containerization Platform": Docker is a platform that allows developers to package applications and their dependencies into isolated environments called containers. These containers can run anywhere, ensuring consistency across various environments like development, testing, and production.

"Lightweight Virtualization": Docker containers are much lighter than traditional virtual machines because they share the host operating system’s kernel instead of requiring a full OS for each instance. This reduces the overhead and enables fast startup times.

"Portable Application Packaging": Docker allows developers to bundle their application, along with all necessary libraries, binaries, and configurations, into a portable container image. These images can be easily shared and deployed across different systems without worrying about environment inconsistencies.

"Isolation and Security": Each Docker container runs in isolation from others, providing security and stability. The application in a container has its own file system, network, and process tree, ensuring that containers don’t interfere with each other or the host system.

"Simplifies DevOps (CI/CD)": Docker plays a crucial role in modern DevOps practices. By using containers in CI/CD pipelines, development teams can quickly test, deploy, and roll back changes with confidence that the application will behave the same across environments.

"Microservices Architecture": Docker supports the microservices model, where large applications are split into smaller, independent services, each running in its own container. This enables easy scaling, independent updates, and more modular software design.

"Community and Ecosystem": Docker has a huge ecosystem of tools, integrations, and community support. The Docker Hub provides a repository of ready-made container images for common applications, reducing the time needed to build environments from scratch.


2. why we use Docker ?

"Portability": Docker containers package the application with all its dependencies, libraries, and environment settings, allowing it to run consistently across different environments (local, test, production) without configuration changes or compatibility issues.

"Efficiency": Unlike traditional virtual machines that require a full OS, Docker containers share the host OS’s kernel, making them lightweight and faster to start. This allows multiple containers to run on a single host with minimal resource overhead.

"Fast Deployment": Docker enables rapid application deployment by packaging code and its environment together. Containers can be spun up in seconds, enabling faster development, testing, and deployment cycles. Rolling back to previous versions is also simple with versioned images.

"Isolation": Each Docker container runs in its own isolated environment with its own file system, network, and process space. This ensures that applications won’t interfere with each other, providing security and stability, especially when multiple apps run on the same host.

"Scalability": Docker integrates well with container orchestration tools like Kubernetes, making it easy to scale applications horizontally. You can quickly spin up multiple replicas of containers to handle increased traffic or workload, enabling seamless scaling.

"Consistency": Docker eliminates the "works on my machine" problem by bundling the app and its dependencies into a single image. This ensures that the application behaves the same across all environments (development, testing, and production).

"CI/CD Integration": Docker fits naturally into CI/CD pipelines by allowing you to create consistent environments for testing and deployment. The same container images can be used throughout the development process, ensuring that what passes in testing will work in production.









**********************************docker-installation**********************************

https://docs.docker.com/engine/install/








***********************************Docker-HUB***********************************
* * Docker Hub is a service provided by Docker for finding and sharing
* * container images with your team. Learn more and find images
* * at https://hub.docker.com


* * Login into Docker
docker login -u <username>

* * Publish an image to Docker Hub
docker push <username>/<image_name>

* * Search Hub for an image
docker search <image_name>

* * Pull an image from a Docker Hub
docker pull <image_name>

* * Get help with Docker. Can also use –help on all subcommands
docker --help

* * Display system-wide information
docker info








***************************************Basic-commands*************************************


* *List running containers
docker ps  

* * List all docker containers (running and stopped):
docker ps --all

* *Build an Image from a Dockerfile
docker build -t <image_name>

* * Build an Image from a Dockerfile without the cache
docker build -t <image_name> . –no-cache

* * Build an image from Dockerfile in current directory
docker build --tag myimage:01 . 
docker build --tag myimage:02 . 

* * List local images
docker images

* * Start or stop an existing container
docker start|stop <container_name> (or <container-id>)

* * Delete an Image
docker rmi <image_name>

* *Restart a container
docker restart <container name>

* * Remove a stopped container
docker rm <container_name>

* * kill he container 
docker kill <container_name>

* * Destroy the container
docker rm -f <container_name>

* * suspend container
docker pause

* * resume container
docker unpause

* * Remove all unused images
docker image prune
docker rmi $(docker images \ -q -f "dangling=true")

* * Run a container in the background
docker run -d <image_name>

* * Open a shell inside a running container
docker exec -it <container_name> sh

* * Run a container from the Ubuntu image and open a bash shell inside it
docker run -it ubuntu bash

* * Run a container with and publish a container’s port(s) to the host.
docker run -p <host_port>:<container_port> -d <image_name> 
docker run -p <host_port>:<container_port> <image_name>

* * Create and run a container from an image, with a custom name:
docker run --name <container_name> <image_name>

* * Start the docker daemon
docker -d 

* * The docker history command is used to view the history of an image, showing the layers and commands used to build
(--no-trunc: Don’t truncate the output.)
(-q, --quiet: Only show image IDs.)
docker history <image_name> 


* * The docker save command is used to export one or more Docker images to a tar archive. This is useful for saving and sharing images without needing to re-pull them from a remote registry.

* * Save an Image to a Tar File
docker save -o my_redis_image.tar redis

* * Save Multiple Images to a Tar File
docker save -o my_images.tar redis alpine nginx

* * Save an Image and Pipe to Gzip for Compression
docker save redis | gzip > redis_image.tar.gz







**************************************inspect-container*************************************



* * Fetch and follow the logs of a container ,live logs
docker logs -f <container_name>

* * Show exposed ports of a container
docker port <container_id> 

* * To inspect a running container
docker inspect <container_name> (or <container_id>)

* * View resource usage stats
docker container stats

* *Check docker daemon disk space usage
docker system df

* *Remove images, networks, containers, and volumes
docker system prune -af

* * show the diffrences with the images (modified files)
docker diff <container_name>

* * list the process runnnig on the container 
docker top <container_name>






**************************************Docker volumes*************************************

* * List volumes
docker volume ls

* * Create a local volume
docker volume create --name <volume_name>

* *  Inspect a Volume (This shows detailed information about the volume, including the mount point, driver, and any containers using it)
docker volume inspect my_volume

* *  Mounting a volume on container start (Mount /host/path from the host into /container/path inside the container)
docker run -v <volume_name>:/data <image-name>
ex->> docker run -v /host/path:/container/path nginx

* * Use a Volume When Running a Container (This runs an nginx container with the volume my_volume mounted at the /data directory inside the container.)
docker run -d --name my_container -v my_volume:/data nginx

* * Mount a Volume at a Specific Path
docker run -d --name my_container -v /my/local/path:/data nginx

* * Destroy a volume
docker volume rm <volume_name>

* * Run a Container with Multiple Volumes (This runs a container with two volumes my_volume mounted at /data ;;Host directory 
* * /my/local/path mounted at /config)
docker run -d --name my_container -v my_volume:/data -v /my/local/path:/config nginx








**************************************Docker copy-commands*************************************


* * Copy from Host to Container
docker cp <source-path-on-host> <container-name-or-id>:<destination-path-in-container>
exe=docker cp /path/on/host/file.txt my_container:/path/in/container/

* * Copy from Container to Host
docker cp <container-name-or-id>:<source-path-in-container> <destination-path-on-host>
exe=docker cp my_container:/path/in/container/file.txt /path/on/host/

* * Copy a Directory from Host to Container
docker cp /path/on/host/my_directory my_container:/path/in/container/

* * Copy a Directory from Container to Host
docker cp my_container:/path/in/container/my_directory /path/on/host/







**************************************export-commands*************************************


* * The docker export command is used to export the filesystem of a container as a tarball (archive) without the image layers or history. It creates a snapshot of the container's filesystem at the current state.

* * This command exports the filesystem of a running or stopped container into a .tar file
docker export -o container_backup.tar my_container

* * if you want to export the filesystem and view it directly or pipe it to another command
docker export my_container > container_backup.tar






**************************************Docker Network*************************************

* * List All Docker Networks
docker network ls

* * Create a local network
docker network create <network_name>

* * Attach a container to a network on start
docker run -d --net <network_name> <image-name>

* * Create a Container and Attach it to a Specific Network
docker run -d --name my-app --network my-network nginx

* * Connect a running container from a network
docker network connect <network_name> <container_id>

* * Attach Multiple Networks to a Container
docker network connect my-network1 my-container
docker network connect my-network2 my-container

* *Run a Container with a Static IP
"This command creates a network with a specific subnet (my-static-network) and runs a container with a static IP address (172.18.0.10) on that network."

docker network create --subnet=172.18.0.0/16 my-static-network
docker run -d --name my-app --network my-static-network --ip 172.18.0.10 nginx


* * Disconnect container to a network
docker network disconnect <network_name> <container_id>

* * Disconnect All Containers from a Network
docker network disconnect -f my-network $(docker ps -q)

* * Query a specific metadata of a running container
docker inspect -f '{{ .NetworkSettings.IPAddress }}' <container_id>

* * Disconnect a Container from a Network
docker network inspect my_network

* * Remove a Network
docker network rm my_network




**************Example: Multi-option Docker Run Command*************
docker run \
  --name my-container \
  --network my-network \
  -d \
  -p 8080:80 \
  -e MYSQL_ROOT_PASSWORD=rootpassword \
  -e MYSQL_DATABASE=mydb \
  -v /my/local/data:/var/lib/mysql \
  --restart always \
  mysql:5.7


* * Explanation:

docker run \ — Starts the Docker run command.

--name my-container \ — Sets the container name to my-container.

--network my-network \ — Connects the container to the my-network network.

-d \ — Runs the container in detached mode (in the background).

-p 8080:80 \ — Maps port 8080 on the host to port 80 on the container.

-e MYSQL_ROOT_PASSWORD=rootpassword \ — Sets the environment variable MYSQL_ROOT_PASSWORD with the value rootpassword.

-e MYSQL_DATABASE=mydb \ — Sets another environment variable MYSQL_DATABASE with the value mydb.

-v /my/local/data:/var/lib/mysql \ — Mounts a volume from the host (/my/local/data) to the container (/var/lib/mysql).

--restart always \ — Configures the container to always restart if it stops.

mysql:5.7 — Specifies the Docker image and version to run (mysql:5.7).












*************************************How to make Dockerfile*************************************
A Dockerfile is a text document that contains a series of instructions on how to build a Docker image. Docker reads the Dockerfile to create an image with the environment and configuration you need for your applications.


FROM image                  "base image for the build"
    FROM ubuntu:20.04

LABEL (Metadata)            Used to add metadata to the image, like maintainer information.
    LABEL maintainer="your-email@example.com"

COPY path dst               Copies files from your host system to the image.
    COPY ./local-file /app/remote-file

ADD path dst                Similar to COPY, but it can also extract compressed files (like .tar.gz) and copy them directly into the container.
    ADD myapp.tar.gz /app

RUN args                    Executes commands in the container at build time and commits the results to the image.
    RUN apt-get update && apt-get install -y curl

USER name                   set the default username

WORKDIR path                Sets the working directory inside the container for subsequent instructions like RUN, CMD, ENTRYPOINT
    WORKDIR /app


CMD args                    Provides default commands to be executed when a container starts. If overridden
    CMD ["node", "app.js"]

EXPOSE xxxx xxxx            Informs Docker that the container will listen on the specified network ports at runtime.
    EXPOSE 8080 

VOLUME  mp                    Declares a mount point, so Docker can store data in a volume
    VOLUME ["/data"]






************Dockerfile Example**************

"1. Dockerfile for a Node.js Application"

* * Use an official Node.js runtime as a parent image
FROM node:14

* * Set the working directory inside the container
WORKDIR /app

* * Copy the package.json and package-lock.json files into the container
COPY package*.json ./

* * Install dependencies
RUN npm install

* * Copy the rest of the application code into the container
COPY . .

* * Set environment variables
ENV NODE_ENV=production

* * Expose the app's port
EXPOSE 3000

* * Start the application
CMD ["npm", "start"]



"2. Dockerfile for a Python Flask Application"
* * Use an official Python runtime as a parent image
FROM python:3.9-slim

* * Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

* * Set the working directory inside the container
WORKDIR /app

* * Install dependencies from requirements.txt
COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

* * Copy the rest of the application code into the container
COPY . .

* * Expose the port the app runs on
EXPOSE 5000

* * Run the Flask app
CMD ["python", "app.py"]


"3. Dockerfile for a Java Spring Boot Application"
* * Use an official OpenJDK image as a parent image
FROM openjdk:11-jdk-slim

* * Set the working directory inside the container
WORKDIR /app

* * Add the JAR file to the container
COPY target/myapp-0.0.1-SNAPSHOT.jar app.jar

* * Expose the port the app runs on
EXPOSE 8080

* * Run the Spring Boot app
ENTRYPOINT ["java", "-jar", "app.jar"]


"4. Dockerfile for an Nginx-based Static Website"
* * Use the official Nginx image as a base image
FROM nginx:alpine

* * Copy static website files to the default Nginx public directory
COPY ./public /usr/share/nginx/html

* * Expose port 80
EXPOSE 80


"5. Dockerfile for a .NET Core Application"
* * Use the .NET SDK to build the app
FROM mcr.microsoft.com/dotnet/sdk:6.0 AS build
WORKDIR /app

* * Copy and restore dependencies
COPY *.csproj ./
RUN dotnet restore

* * Copy the rest of the application code
COPY . ./
RUN dotnet publish -c Release -o out

* * Use the .NET Runtime image for the final image
FROM mcr.microsoft.com/dotnet/aspnet:6.0 AS runtime
WORKDIR /app
COPY --from=build /app/out ./

* * Expose the port the app runs on
EXPOSE 80

* * Run the .NET Core app
ENTRYPOINT ["dotnet", "MyApp.dll"]


"6. Dockerfile for a PHP and Apache Application"
* * Use an official PHP-Apache image as a base image
FROM php:7.4-apache

* * Copy application files into the default web root directory
COPY ./src /var/www/html/

* * Set file permissions
RUN chown -R www-data:www-data /var/www/html

* * Enable mod_rewrite for Apache
RUN a2enmod rewrite

* * Expose the web server port
EXPOSE 80

* * Start Apache in the foreground
CMD ["apache2-foreground"]


"7. Dockerfile for a Ruby on Rails Application"

* * Use the official Ruby image
FROM ruby:2.7

* * Install dependencies
RUN apt-get update -qq && apt-get install -y nodejs postgresql-client

* * Set the working directory inside the container
WORKDIR /app

* * Copy the Gemfile and Gemfile.lock and install gems
COPY Gemfile Gemfile.lock ./
RUN bundle install

* * Copy the rest of the application code into the container
COPY . .

* * Expose the Rails server port
EXPOSE 3000

* * Start the Rails server
CMD ["rails", "server", "-b", "0.0.0.0"]


"8. Dockerfile for a React.js Frontend Application"
* * Use Node.js for building the React app
FROM node:16 AS build

WORKDIR /app

* * Install dependencies
COPY package*.json ./
RUN npm install

* * Copy the rest of the application code
COPY . .

* * Build the React app for production
RUN npm run build

* * Use Nginx to serve the built files
FROM nginx:alpine

COPY --from=build /app/build /usr/share/nginx/html

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]






**********Advanced Examples of Dockerfile*************


"1. Dockerfile for Production-Ready Node.js Application"
This Dockerfile example optimizes the build for a production Node.js application using multi-stage builds and non-root users.

* * Stage 1: Build the app
FROM node:16 AS builder

* * Set the working directory
WORKDIR /app

* * Install dependencies first to leverage Docker's caching mechanism
COPY package*.json ./
RUN npm install --production

* * Copy the rest of the application code
COPY . .

* * Build the app for production
RUN npm run build

* * Stage 2: Create a minimal production image
FROM node:16-alpine

* * Set a non-root user for better security
RUN addgroup -S appgroup && adduser -S appuser -G appgroup
USER appuser

* * Set the working directory
WORKDIR /app

* * Copy only the necessary files from the builder stage
COPY --from=builder /app/build /app

* * Expose the app port
EXPOSE 3000

* * Set environment variables
ENV NODE_ENV=production

* * Run the application
CMD ["npm", "start"]


"2. Dockerfile for a Microservice (Python Flask + Gunicorn)"
This example demonstrates a Dockerfile for a Python Flask microservice that uses Gunicorn for production readiness.

* * Stage 1: Base image
FROM python:3.9-slim AS base

* * Set environment variables to disable buffering
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

* * Install dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    libpq-dev \
    --no-install-recommends && \
    rm -rf /var/lib/apt/lists/*

* * Set a working directory
WORKDIR /app

* * Install Python dependencies
COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

* * Stage 2: Application code
FROM base AS final

* * Copy the application code into the container
COPY . .

* * Expose the app port
EXPOSE 5000

* * Command to run the app
CMD ["gunicorn", "--bind", "0.0.0.0:5000", "app:app"]


"3. Dockerfile for a Java Spring Boot Microservice with Multi-Stage Build"
This example shows a production-grade Spring Boot Dockerfile using multi-stage builds to reduce the final image size.

* * Stage 1: Build the app
FROM maven:3.8.4-openjdk-11 AS build

* * Set working directory
WORKDIR /app

* * Copy pom.xml and install dependencies
COPY pom.xml .
RUN mvn dependency:go-offline

* * Copy the source code and build the app
COPY src ./src
RUN mvn package -DskipTests

* * Stage 2: Create a minimal runtime image
FROM openjdk:11-jre-slim

* * Set working directory
WORKDIR /app

* * Copy only the JAR file from the build stage
COPY --from=build /app/target/myapp.jar ./myapp.jar

* * Expose the application port
EXPOSE 8080

* * Run the JAR file
CMD ["java", "-jar", "myapp.jar"]



"4. Dockerfile for a CI/CD Pipeline (Node.js + Alpine + Docker)"
This Dockerfile example is designed for building Node.js applications within a CI/CD environment. It integrates Docker into the build process using the Docker-in-Docker (DinD) technique.

* * Stage 1: Build the Node.js app
FROM node:16-alpine AS builder

* * Install dependencies
WORKDIR /app
COPY package*.json ./
RUN npm install --production

* * Copy the rest of the application code
COPY . .
RUN npm run build

* * Stage 2: DinD (Docker in Docker) for CI/CD
FROM docker:20.10.7-dind

* * Install Docker client and Node.js runtime
RUN apk add --no-cache nodejs npm

* * Copy the built files from the previous stage
WORKDIR /app
COPY --from=builder /app /app

* * Expose the Docker daemon for CI/CD tools like Jenkins or GitLab CI
EXPOSE 2375

* * Start Docker daemon and app
CMD ["dockerd-entrypoint.sh"]


